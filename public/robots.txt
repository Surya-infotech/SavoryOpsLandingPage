# SavoryOps Robots.txt

# Allow all web crawlers to access the main website
User-agent: *
Allow: /

# Disallow access to admin areas (if any)
Disallow: /admin/
Disallow: /private/
Disallow: /api/

# Disallow access to development files
Disallow: /node_modules/
Disallow: /src/
Disallow: /.git/
Disallow: /.env
Disallow: /package.json
Disallow: /package-lock.json

# Disallow access to sensitive files
Disallow: /*.log
Disallow: /*.sql
Disallow: /*.bak
Disallow: /*.tmp

# Block all subdomains
User-agent: *
Disallow: https://*.savoryops.com/

# Sitemap location for main website
Sitemap: https://savoryops.com/sitemap.xml

# Additional sitemaps (if you have multiple)
# Sitemap: https://savoryops.com/sitemap-blog.xml
# Sitemap: https://savoryops.com/sitemap-features.xml